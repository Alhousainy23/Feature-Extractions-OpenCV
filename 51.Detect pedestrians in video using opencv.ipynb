{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import seaborn as sns \n",
    "import scipy as sc \n",
    "import pandas as pd \n",
    "from imutils.object_detection import non_max_suppression\n",
    "os.chdir(R\"D:\\\\AI\\\\AI Models\\\\3. OpenCV\\\\0- OpenCV\\\\Data\\\\Images\")\n",
    "filename = 'vtest.AVI'\n",
    "file_size = (1920,1080)#Assumes 1920 * 1080 MP4\n",
    "scale_ratio = 1 # Option to scale to fraction of original size. \n",
    "#We want to save the output to a video file \n",
    "output_filename = 'Pedestrians_on_street.mp4'\n",
    "output_frame_per_second = 20.0\n",
    "def main():\n",
    "    #Create a HOG Descriptor \n",
    "    hog = cv.HOGDescriptor()\n",
    "    #Initialize The People detector \n",
    "    hog.setSVMDetector(cv.HOGDescriptor_getDefaultPeopleDetector())\n",
    "    #Load Video \n",
    "    cap = cv.VideoCapture(filename)\n",
    "    #Create Video Writer object so we can save the video output \n",
    "    fourcc = cv.VideoWriter_fourcc(*'mp4v')#XVID\n",
    "    result = cv.VideoWriter(output_filename,fourcc,output_frame_per_second,file_size)\n",
    "    #Process The Video\n",
    "    while cap.isOpened():\n",
    "        #Capture one frame at a time \n",
    "        success , frame = cap.read()\n",
    "        #Do we have a video frame ? if true , proceed.\n",
    "        if success:\n",
    "            # Resize the frame\n",
    "            width = int(frame.shape[1] * scale_ratio)\n",
    "            height = int(frame.shape[0] * scale_ratio)\n",
    "            frame = cv.resize(frame, (width, height))\n",
    "            #Store the original frame\n",
    "            orig_frame = frame.copy()\n",
    "            (bounding_boxes , weights) = hog.detectMultiScale(frame,winStride=(16,16),padding=(8,8),scale=1.05)\n",
    "            # Draw bounding boxes on the frame \n",
    "            for (x,y,w,h) in bounding_boxes:cv.rectangle(orig_frame,(x,y),(x+w,y+h),(0,0,255),4)\n",
    "            #Get rid of ovelapping bounding boxes \n",
    "            #You can to waek the ovelapThresh value for better results \n",
    "            bounding_boxes= np.array([[x,y,x+w,y+h] for (x,y,w,h) in bounding_boxes])\n",
    "            selection = non_max_suppression(bounding_boxes)\n",
    "            #Draw The final bounding boxes \n",
    "            for (x1,y1,x2,y2) in selection : cv.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),4)\n",
    "            #Write the frame to the output video file \n",
    "            result.write(frame)\n",
    "            #Display The Frame \n",
    "            cv.imshow(\"Frame\",frame)\n",
    "            #Display frame for x milliseconds and check if q key is pressed \n",
    "            #q == quit \n",
    "            if cv.waitKey(1)==ord ('q'): break \n",
    "            #No More video frames left \n",
    "        else: break \n",
    "    #Stop when the video is finished\n",
    "    cap.release()\n",
    "    #release the video recording\n",
    "    result.release()\n",
    "    #Close all windows\n",
    "    cv.destroyAllWindows()\n",
    "main()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # Import the OpenCV library to enable computer vision\n",
    "import numpy as np # Import the NumPy scientific computing library\n",
    "from imutils.object_detection import non_max_suppression # Handle overlapping\n",
    "import os \n",
    "os.chdir(R\"D:\\\\AI\\\\AI Models\\\\3. OpenCV\\\\0- OpenCV\\\\Data\\\\Images\")\n",
    "# Make sure the video file is in the same directory as your code\n",
    "filename = 'vtest.AVI'\n",
    "file_size = (1920,1080) # Assumes 1920x1080 mp4\n",
    "scale_ratio = 1 # Option to scale to fraction of original size. \n",
    "# We want to save the output to a video file\n",
    "output_filename = 'pedestrians_on_street.mp4'\n",
    "output_frames_per_second = 20.0\n",
    "def main():\n",
    "  # Create a HOGDescriptor object\n",
    "  hog = cv2.HOGDescriptor()\n",
    "  # Initialize the People Detector\n",
    "  hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())    \n",
    "  # Load a video\n",
    "  cap = cv2.VideoCapture(filename)\n",
    "  # Create a VideoWriter object so we can save the video output\n",
    "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "  result = cv2.VideoWriter(output_filename,fourcc,output_frames_per_second,file_size) \n",
    "  # Process the video\n",
    "  while cap.isOpened():\n",
    "    # Capture one frame at a time\n",
    "    success, frame = cap.read() \n",
    "    # Do we have a video frame? If true, proceed.\n",
    "    if success:\n",
    "    # Resize the frame\n",
    "      width = int(frame.shape[1] * scale_ratio)\n",
    "      height = int(frame.shape[0] * scale_ratio)\n",
    "      frame = cv2.resize(frame, (width, height))\n",
    "       # Store the original frame\n",
    "      orig_frame = frame.copy()            \n",
    "      # Detect people\n",
    "      # image: a single frame from the video\n",
    "      # winStride: step size in x and y direction of the sliding window\n",
    "      # padding: no. of pixels in x and y direction for padding of \n",
    "      # sliding window\n",
    "      # scale: Detection window size increase coefficient   \n",
    "      # bounding_boxes: Location of detected people\n",
    "      # weights: Weight scores of detected people\n",
    "      # Tweak these parameters for better results\n",
    "      (bounding_boxes, weights) = hog.detectMultiScale(frame,winStride=(16, 16),padding=(4, 4),scale=1.05)\n",
    "      # Draw bounding boxes on the frame\n",
    "      for (x, y, w, h) in bounding_boxes: \n",
    "        cv2.rectangle(orig_frame,(x, y),(x + w, y + h),(0, 0, 255),2)\n",
    "      # Get rid of overlapping bounding boxes\n",
    "      # You can tweak the overlapThresh value for better results\n",
    "      bounding_boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in bounding_boxes])\n",
    "      selection = non_max_suppression(bounding_boxes,probs=None,overlapThresh=0.45)\n",
    "      # draw the final bounding boxes\n",
    "      for (x1, y1, x2, y2) in selection:\n",
    "        cv2.rectangle(frame,(x1, y1),(x2, y2),(0, 255, 0),4)\n",
    "      # Write the frame to the output video file\n",
    "      result.write(frame)\n",
    "      # Display the frame \n",
    "      cv2.imshow(\"Frame\", frame)    \n",
    "      # Display frame for X milliseconds and check if q key is pressed\n",
    "      # q == quit\n",
    "      if cv2.waitKey(25) & 0xFF == ord('q'):break   \n",
    "    # No more video frames left\n",
    "    else:break           \n",
    "  # Stop when the video is finished\n",
    "  cap.release()\n",
    "  # Release the video recording\n",
    "  result.release()\n",
    "  # Close all windows\n",
    "  cv2.destroyAllWindows() \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
